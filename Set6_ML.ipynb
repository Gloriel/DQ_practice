{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "admissions = pd.read_csv(\"admissions.csv\")\n",
    "plt.scatter(admissions['gpa'], admissions['admit'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(admissions[[\"gpa\"]], admissions[\"admit\"])\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(admissions[[\"gpa\"]], admissions[\"admit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(admissions[[\"gpa\"]], admissions[\"admit\"])\n",
    "pred_probs = logistic_model.predict_proba(admissions[[\"gpa\"]])\n",
    "plt.scatter(admissions[\"gpa\"], pred_probs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(admissions[[\"gpa\"]], admissions[\"admit\"])\n",
    "fitted_labels = logistic_model.predict(admissions[[\"gpa\"]])\n",
    "plt.scatter(admissions[\"gpa\"], fitted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "admissions = pd.read_csv(\"admissions.csv\")\n",
    "model = LogisticRegression()\n",
    "model.fit(admissions[[\"gpa\"]], admissions[\"admit\"])\n",
    "admissions = pd.read_csv(\"admissions.csv\")\n",
    "model = LogisticRegression()\n",
    "model.fit(admissions[[\"gpa\"]], admissions[\"admit\"])\n",
    "\n",
    "labels = model.predict(admissions[[\"gpa\"]])\n",
    "admissions[\"predicted_label\"] = labels\n",
    "print(admissions[\"predicted_label\"].value_counts())\n",
    "print(admissions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions[\"actual_label\"] = admissions[\"admit\"]\n",
    "matches = admissions[\"predicted_label\"] == admissions[\"actual_label\"]\n",
    "correct_predictions = admissions[matches]\n",
    "print(correct_predictions.head())\n",
    "accuracy = len(correct_predictions) / len(admissions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive_filter = (admissions[\"predicted_label\"] == 1) & (admissions[\"actual_label\"] == 1)\n",
    "true_positives = len(admissions[true_positive_filter])\n",
    "\n",
    "true_negative_filter = (admissions[\"predicted_label\"] == 0) & (admissions[\"actual_label\"] == 0)\n",
    "true_negatives = len(admissions[true_negative_filter])\n",
    "\n",
    "print(true_positives)\n",
    "print(true_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the previous screen\n",
    "true_positive_filter = (admissions[\"predicted_label\"] == 1) & (admissions[\"actual_label\"] == 1)\n",
    "true_positives = len(admissions[true_positive_filter])\n",
    "false_negative_filter = (admissions[\"predicted_label\"] == 0) & (admissions[\"actual_label\"] == 1)\n",
    "false_negatives = len(admissions[false_negative_filter])\n",
    "\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "print(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous screens\n",
    "true_positive_filter = (admissions[\"predicted_label\"] == 1) & (admissions[\"actual_label\"] == 1)\n",
    "true_positives = len(admissions[true_positive_filter])\n",
    "false_negative_filter = (admissions[\"predicted_label\"] == 0) & (admissions[\"actual_label\"] == 1)\n",
    "false_negatives = len(admissions[false_negative_filter])\n",
    "true_negative_filter = (admissions[\"predicted_label\"] == 0) & (admissions[\"actual_label\"] == 0)\n",
    "true_negatives = len(admissions[true_negative_filter])\n",
    "false_positive_filter = (admissions[\"predicted_label\"] == 1) & (admissions[\"actual_label\"] == 0)\n",
    "false_positives = len(admissions[false_positive_filter])\n",
    "specificity = (true_negatives) / (false_positives + true_negatives)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "cars = pd.read_csv(\"auto.csv\")\n",
    "print(cars.head())\n",
    "unique_regions = cars[\"origin\"].unique()\n",
    "print(unique_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cylinders = pd.get_dummies(cars[\"cylinders\"], prefix=\"cyl\")\n",
    "cars = pd.concat([cars, dummy_cylinders], axis=1)\n",
    "dummy_years = pd.get_dummies(cars[\"year\"], prefix=\"year\")\n",
    "cars = pd.concat([cars, dummy_years], axis=1)\n",
    "cars = cars.drop(\"year\", axis=1)\n",
    "cars = cars.drop(\"cylinders\", axis=1)\n",
    "print(cars.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shuffled_rows = np.random.permutation(cars.index)\n",
    "shuffled_cars = cars.iloc[shuffled_rows]\n",
    "highest_train_row = int(cars.shape[0] * .70)\n",
    "train = shuffled_cars.iloc[0:highest_train_row]\n",
    "test = shuffled_cars.iloc[highest_train_row:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "unique_origins = cars[\"origin\"].unique()\n",
    "unique_origins.sort()\n",
    "\n",
    "models = {}\n",
    "features = [c for c in train.columns if c.startswith(\"cyl\") or c.startswith(\"year\")]\n",
    "\n",
    "for origin in unique_origins:\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    X_train = train[features]\n",
    "    y_train = train[\"origin\"] == origin\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    models[origin] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_probs = pd.DataFrame(columns=unique_origins)\n",
    "testing_probs = pd.DataFrame(columns=unique_origins)  \n",
    "\n",
    "for origin in unique_origins:\n",
    "    # Select testing features.\n",
    "    X_test = test[features]   \n",
    "    # Compute probability of observation being in the origin.\n",
    "    testing_probs[origin] = models[origin].predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_origins = testing_probs.idxmax(axis=1)\n",
    "print(predicted_origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\", \"origin\", \"car name\"]\n",
    "cars = pd.read_table(\"auto-mpg.data\", delim_whitespace=True, names=columns)\n",
    "filtered_cars = cars[cars['horsepower'] != '?'].copy()\n",
    "filtered_cars['horsepower'] = filtered_cars['horsepower'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def train_and_test(cols):\n",
    "    # Split into features & target.\n",
    "    features = filtered_cars[cols]\n",
    "    target = filtered_cars[\"mpg\"]\n",
    "    # Fit model.\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(features, target)\n",
    "    # Make predictions on training set.\n",
    "    predictions = lr.predict(features)\n",
    "    # Compute MSE and Variance.\n",
    "    mse = mean_squared_error(filtered_cars[\"mpg\"], predictions)\n",
    "    variance = np.var(predictions)\n",
    "    return(mse, variance)\n",
    "    \n",
    "cyl_mse, cyl_var = train_and_test([\"cylinders\"])\n",
    "weight_mse, weight_var = train_and_test([\"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our implementation for train_and_test, takes in a list of strings.\n",
    "def train_and_test(cols):\n",
    "    # Split into features & target.\n",
    "    features = filtered_cars[cols]\n",
    "    target = filtered_cars[\"mpg\"]\n",
    "    # Fit model.\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(features, target)\n",
    "    # Make predictions on training set.\n",
    "    predictions = lr.predict(features)\n",
    "    # Compute MSE and Variance.\n",
    "    mse = mean_squared_error(filtered_cars[\"mpg\"], predictions)\n",
    "    variance = np.var(predictions)\n",
    "    return(mse, variance)\n",
    "\n",
    "one_mse, one_var = train_and_test([\"cylinders\"])\n",
    "two_mse, two_var = train_and_test([\"cylinders\", \"displacement\"])\n",
    "three_mse, three_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "four_mse, four_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "five_mse, five_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"])\n",
    "six_mse, six_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\"])\n",
    "seven_mse, seven_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\",\"model year\", \"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "def train_and_cross_val(cols):\n",
    "    features = filtered_cars[cols]\n",
    "    target = filtered_cars[\"mpg\"]\n",
    "    \n",
    "    variance_values = []\n",
    "    mse_values = []\n",
    "    \n",
    "    # KFold instance.\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=3)\n",
    "    \n",
    "    # Iterate through over each fold.\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        # Training and test sets.\n",
    "        X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "        y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        # Fit the model and make predictions.\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        predictions = lr.predict(X_test)\n",
    "        \n",
    "        # Calculate mse and variance values for this fold.\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        var = np.var(predictions)\n",
    "\n",
    "        # Append to arrays to do calculate overall average mse and variance values.\n",
    "        variance_values.append(var)\n",
    "        mse_values.append(mse)\n",
    "   \n",
    "    # Compute average mse and variance values.\n",
    "    avg_mse = np.mean(mse_values)\n",
    "    avg_var = np.mean(variance_values)\n",
    "    return(avg_mse, avg_var)\n",
    "        \n",
    "two_mse, two_var = train_and_cross_val([\"cylinders\", \"displacement\"])\n",
    "three_mse, three_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "four_mse, four_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "five_mse, five_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"])\n",
    "six_mse, six_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\"])\n",
    "seven_mse, seven_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\",\"model year\", \"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've hidden the `train_and_cross_val` function to save space but you can still call the function!\n",
    "import matplotlib.pyplot as plt\n",
    "        \n",
    "two_mse, two_var = train_and_cross_val([\"cylinders\", \"displacement\"])\n",
    "three_mse, three_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "four_mse, four_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "five_mse, five_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"])\n",
    "six_mse, six_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\"])\n",
    "seven_mse, seven_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\",\"model year\", \"origin\"])\n",
    "plt.scatter([2,3,4,5,6,7], [two_mse, three_mse, four_mse, five_mse, six_mse, seven_mse], c='red')\n",
    "plt.scatter([2,3,4,5,6,7], [two_var, three_var, four_var, five_var, six_var, seven_var], c='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "votes = pd.read_csv(\"114_congress.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(votes[\"party\"].value_counts())\n",
    "print(votes.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "print(euclidean_distances(votes.iloc[0,3:].values.reshape(1, -1), votes.iloc[1,3:].values.reshape(1, -1)))\n",
    "distance = euclidean_distances(votes.iloc[0,3:].values.reshape(1, -1), votes.iloc[2,3:].values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=2, random_state=1)\n",
    "senator_distances = kmeans_model.fit_transform(votes.iloc[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans_model.labels_\n",
    "print(pd.crosstab(labels, votes[\"party\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "democratic_outliers = votes[(labels == 1) & (votes[\"party\"] == \"D\")]\n",
    "print(democratic_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=senator_distances[:,0], y=senator_distances[:,1], c=labels, linewidths=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extremism = (senator_distances ** 3).sum(axis=1)\n",
    "votes[\"extremism\"] = extremism\n",
    "votes.sort_values(\"extremism\", inplace=True, ascending=False)\n",
    "print(votes.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nba = pd.read_csv(\"nba_2013.csv\")\n",
    "nba.head(3)\n",
    "point_guards = nba[nba['pos'] == 'PG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_guards['ppg'] = point_guards['pts'] / point_guards['g']\n",
    "\n",
    "# Sanity check, make sure ppg = pts/g\n",
    "point_guards[['pts', 'g', 'ppg']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_guards = point_guards[point_guards['tov'] != 0]\n",
    "point_guards['atr'] = point_guards['ast'] / point_guards['tov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(point_guards['ppg'], point_guards['atr'], c='y')\n",
    "plt.title(\"Point Guards\")\n",
    "plt.xlabel('Points Per Game', fontsize=13)\n",
    "plt.ylabel('Assist Turnover Ratio', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 5\n",
    "# Use numpy's random function to generate a list, length: num_clusters, of indices\n",
    "random_initial_points = np.random.choice(point_guards.index, size=num_clusters)\n",
    "# Use the random indices to create the centroids\n",
    "centroids = point_guards.loc[random_initial_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(point_guards['ppg'], point_guards['atr'], c='yellow')\n",
    "plt.scatter(centroids['ppg'], centroids['atr'], c='red')\n",
    "plt.title(\"Centroids\")\n",
    "plt.xlabel('Points Per Game', fontsize=13)\n",
    "plt.ylabel('Assist Turnover Ratio', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroids_to_dict(centroids):\n",
    "    dictionary = dict()\n",
    "    # iterating counter we use to generate a cluster_id\n",
    "    counter = 0\n",
    "\n",
    "    # iterate a pandas data frame row-wise using .iterrows()\n",
    "    for index, row in centroids.iterrows():\n",
    "        coordinates = [row['ppg'], row['atr']]\n",
    "        dictionary[counter] = coordinates\n",
    "        counter += 1\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "centroids_dict = centroids_to_dict(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_distance(centroid, player_values):\n",
    "    root_distance = 0\n",
    "    \n",
    "    for x in range(0, len(centroid)):\n",
    "        difference = centroid[x] - player_values[x]\n",
    "        squared_difference = difference**2\n",
    "        root_distance += squared_difference\n",
    "\n",
    "    euclid_distance = math.sqrt(root_distance)\n",
    "    return euclid_distance\n",
    "\n",
    "q = [5, 2]\n",
    "p = [3,1]\n",
    "\n",
    "# Sqrt(5) = ~2.24\n",
    "print(calculate_distance(q, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing clusters\n",
    "def visualize_clusters(df, num_clusters):\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "\n",
    "    for n in range(num_clusters):\n",
    "        clustered_df = df[df['cluster'] == n]\n",
    "        plt.scatter(clustered_df['ppg'], clustered_df['atr'], c=colors[n-1])\n",
    "        plt.xlabel('Points Per Game', fontsize=13)\n",
    "        plt.ylabel('Assist Turnover Ratio', fontsize=13)\n",
    "    plt.show()\n",
    "\n",
    "visualize_clusters(point_guards, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the function, `assign_to_cluster`\n",
    "# This creates the column, `cluster`, by applying assign_to_cluster row-by-row\n",
    "# Uncomment when ready\n",
    "\n",
    "# point_guards['cluster'] = point_guards.apply(lambda row: assign_to_cluster(row), axis=1)\n",
    "def assign_to_cluster(row):\n",
    "    lowest_distance = -1\n",
    "    closest_cluster = -1\n",
    "    \n",
    "    for cluster_id, centroid in centroids_dict.items():\n",
    "        df_row = [row['ppg'], row['atr']]\n",
    "        euclidean_distance = calculate_distance(centroid, df_row)\n",
    "        \n",
    "        if lowest_distance == -1:\n",
    "            lowest_distance = euclidean_distance\n",
    "            closest_cluster = cluster_id \n",
    "        elif euclidean_distance < lowest_distance:\n",
    "            lowest_distance = euclidean_distance\n",
    "            closest_cluster = cluster_id\n",
    "    return closest_cluster\n",
    "\n",
    "point_guards['cluster'] = point_guards.apply(lambda row: assign_to_cluster(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_centroids(df):\n",
    "    new_centroids_dict = dict()\n",
    "    # 0..1...2...3...4\n",
    "    for cluster_id in range(0, num_clusters):\n",
    "        # Finish the logic\n",
    "        return new_centroids_dict\n",
    "\n",
    "centroids_dict = recalculate_centroids(point_guards)\n",
    "def recalculate_centroids(df):\n",
    "    new_centroids_dict = dict()\n",
    "    \n",
    "    for cluster_id in range(0, num_clusters):\n",
    "        values_in_cluster = df[df['cluster'] == cluster_id]\n",
    "        # Calculate new centroid using mean of values in the cluster\n",
    "        new_centroid = [np.average(values_in_cluster['ppg']), np.average(values_in_cluster['atr'])]\n",
    "        new_centroids_dict[cluster_id] = new_centroid\n",
    "    return new_centroids_dict\n",
    "\n",
    "centroids_dict = recalculate_centroids(point_guards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_guards['cluster'] = point_guards.apply(lambda row: assign_to_cluster(row), axis=1)\n",
    "visualize_clusters(point_guards, num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_dict = recalculate_centroids(point_guards)\n",
    "point_guards['cluster'] = point_guards.apply(lambda row: assign_to_cluster(row), axis=1)\n",
    "visualize_clusters(point_guards, num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(point_guards[['ppg', 'atr']])\n",
    "point_guards['cluster'] = kmeans.labels_\n",
    "\n",
    "visualize_clusters(point_guards, num_clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
