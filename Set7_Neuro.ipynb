{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = make_regression(n_samples=100, n_features=3, random_state=1)\n",
    "\n",
    "features = pd.DataFrame(data[0])\n",
    "labels = pd.Series(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment after you've implemented train() and feedforward()\n",
    "# train_weights = train(features, labels)\n",
    "# linear_predictions = feedforward(features, train_weights)\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "features[\"bias\"] = 1\n",
    "\n",
    "def train(features, labels):\n",
    "    lr = SGDRegressor()\n",
    "    lr.fit(features, labels)\n",
    "    weights = lr.coef_\n",
    "    return weights\n",
    "    \n",
    "def feedforward(features, weights):\n",
    "    predictions = np.dot(features, weights.T)\n",
    "    return predictions\n",
    "\n",
    "train_weights = train(features, labels)\n",
    "linear_predictions = feedforward(features, train_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "class_data = make_classification(n_samples=100, n_features=4, random_state=1)\n",
    "class_features = pd.DataFrame(class_data[0])\n",
    "class_labels = pd.Series(class_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "class_data = make_classification(n_samples=100, n_features=4, random_state=1)\n",
    "class_features = pd.DataFrame(class_data[0])\n",
    "class_labels = pd.Series(class_data[1])\n",
    "\n",
    "# Uncomment this code when you're ready to test your functions.\n",
    "# log_train_weights = log_train(class_features, class_labels)\n",
    "# log_predictions = log_feedforward(class_features, log_train_weights)\n",
    "class_features[\"bias\"] = 1\n",
    "\n",
    "def log_train(class_features, class_labels):\n",
    "    sg = SGDClassifier()\n",
    "    sg.fit(class_features, class_labels)\n",
    "    return sg.coef_\n",
    "\n",
    "def sigmoid(linear_combination):\n",
    "    return 1/(1+np.exp(-linear_combination))\n",
    "\n",
    "def log_feedforward(class_features, log_train_weights):\n",
    "    linear_combination = np.dot(class_features, log_train_weights.T)\n",
    "    log_predictions = sigmoid(linear_combination)\n",
    "    log_predictions[log_predictions >= 0.5] = 1\n",
    "    log_predictions[log_predictions < 0.5] = 0\n",
    "    return log_predictions\n",
    "\n",
    "log_train_weights = log_train(class_features, class_labels)\n",
    "log_predictions = log_feedforward(class_features, log_train_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "x = np.linspace(-2, 2, 20)\n",
    "def relu(values):\n",
    "    return np.maximum(values, 0)\n",
    "\n",
    "relu_y = relu(x)\n",
    "\n",
    "print(x)\n",
    "print(relu_y)\n",
    "\n",
    "plt.plot(x, relu_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2*np.pi, 2*np.pi, 100)\n",
    "tan_y = np.tan(x)\n",
    "plt.plot(x, tan_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-40, 40, 100)\n",
    "tanh_y = np.tanh(x)\n",
    "plt.plot(x, tanh_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import make_moons\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = make_moons(100, random_state=3, noise=0.04)\n",
    "features = pd.DataFrame(data[0])\n",
    "labels = pd.Series(data[1])\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(features[0], features[1], labels)\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(8)\n",
    "\n",
    "data = make_moons(100, random_state=3, noise=0.04)\n",
    "features = pd.DataFrame(data[0])\n",
    "labels = pd.Series(data[1])\n",
    "features[\"bias\"] = 1\n",
    "\n",
    "shuffled_index = np.random.permutation(features.index)\n",
    "shuffled_data = features.loc[shuffled_index]\n",
    "shuffled_labels = labels.loc[shuffled_index]\n",
    "mid_length = int(len(shuffled_data)/2)\n",
    "train_features = shuffled_data.iloc[0:mid_length]\n",
    "test_features = shuffled_data.iloc[mid_length:len(shuffled_data)]\n",
    "train_labels = shuffled_labels.iloc[0:mid_length]\n",
    "test_labels = shuffled_labels.iloc[mid_length: len(labels)]\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(1,), activation='logistic')\n",
    "mlp.fit(train_features, train_labels)\n",
    "nn_predictions = mlp.predict(test_features)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_features, train_labels)\n",
    "log_predictions = lr.predict(test_features)\n",
    "\n",
    "nn_accuracy = accuracy_score(test_labels, nn_predictions)\n",
    "log_accuracy = accuracy_score(test_labels, log_predictions)\n",
    "\n",
    "print(\"Logistic Regression Model Accuracy: \", log_accuracy)\n",
    "print(\"Single Neuron Single Layer NN Model Accuracy: \", nn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8)\n",
    "shuffled_index = np.random.permutation(features.index)\n",
    "shuffled_data = features.loc[shuffled_index]\n",
    "shuffled_labels = labels.loc[shuffled_index]\n",
    "mid_length = int(len(shuffled_data)/2)\n",
    "train_features = shuffled_data.iloc[0:mid_length]\n",
    "test_features = shuffled_data.iloc[mid_length:len(shuffled_data)]\n",
    "train_labels = shuffled_labels.iloc[0:mid_length]\n",
    "test_labels = shuffled_labels.iloc[mid_length: len(labels)]\n",
    "neurons = [1, 5, 10, 15, 20, 25]\n",
    "accuracies = []\n",
    "\n",
    "for n in neurons:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(n,), activation='logistic')\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    nn_predictions = mlp.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, nn_predictions)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [1, 5, 10, 15, 20, 25]\n",
    "nn_accuracies = []\n",
    "\n",
    "for n in neurons:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(n,n), activation='relu', max_iter=1000)\n",
    "    \n",
    "    mlp.fit(train_features, train_labels)\n",
    "    nn_predictions = mlp.predict(test_features)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, nn_predictions)\n",
    "    nn_accuracies.append(accuracy)\n",
    "\n",
    "print(nn_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "digits_data = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.Series(digits_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(digits_data['data'])\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = data.iloc[0]\n",
    "np_image = first_image.values\n",
    "np_image = np_image.reshape(8,8)\n",
    "\n",
    "plt.imshow(np_image, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, 4)\n",
    "\n",
    "axarr[0, 0].imshow(data.iloc[0].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 1].imshow(data.iloc[99].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 2].imshow(data.iloc[199].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 3].imshow(data.iloc[299].values.reshape(8,8), cmap='gray_r')\n",
    "\n",
    "axarr[1, 0].imshow(data.iloc[999].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 1].imshow(data.iloc[1099].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 2].imshow(data.iloc[1199].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 3].imshow(data.iloc[1299].values.reshape(8,8), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 50% Train / test validation\n",
    "def train_knn(nneighbors, train_features, train_labels):\n",
    "    knn = KNeighborsClassifier(n_neighbors = nneighbors)\n",
    "    knn.fit(train_features, train_labels)\n",
    "    return knn\n",
    "\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    overall_accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return overall_accuracy\n",
    "\n",
    "def cross_validate(k):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 4, random_state=2)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = labels.loc[train_index], labels.loc[test_index]\n",
    "        model = train_knn(k, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "    return fold_accuracies\n",
    "        \n",
    "knn_one_accuracies = cross_validate(1)\n",
    "np.mean(knn_one_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(1,10))\n",
    "k_overall_accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    k_accuracies = cross_validate(k)\n",
    "    k_mean_accuracy = np.mean(k_accuracies)\n",
    "    k_overall_accuracies.append(k_mean_accuracy)\n",
    "    \n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. k\")\n",
    "plt.plot(k_values, k_overall_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 50% Train / test validation\n",
    "def train_nn(neuron_arch, train_features, train_labels):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neuron_arch)\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    return mlp\n",
    "\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    overall_accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return overall_accuracy\n",
    "\n",
    "def cross_validate(neuron_arch):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 4, random_state=2)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = labels.loc[train_index], labels.loc[test_index]\n",
    "       \n",
    "        model = train_nn(neuron_arch, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "    return fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_one_neurons = [\n",
    "    (8,),\n",
    "    (16,),\n",
    "    (32,),\n",
    "    (64,),\n",
    "    (128,),\n",
    "    (256,)\n",
    "]\n",
    "nn_one_accuracies = []\n",
    "\n",
    "for n in nn_one_neurons:\n",
    "    nn_accuracies = cross_validate(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_one_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Single Hidden Layer\")\n",
    "\n",
    "x = [i[0] for i in nn_one_neurons]\n",
    "plt.plot(x, nn_one_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_two_neurons = [\n",
    "    (64,64),\n",
    "    (128, 128),\n",
    "    (256, 256)\n",
    "]\n",
    "nn_two_accuracies = []\n",
    "\n",
    "for n in nn_two_neurons:\n",
    "    nn_accuracies = cross_validate(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_two_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Two Hidden Layers\")\n",
    "\n",
    "x = [i[0] for i in nn_two_neurons]\n",
    "plt.plot(x, nn_two_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_two_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 50% Train / test validation\n",
    "def train_nn(neuron_arch, train_features, train_labels):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neuron_arch)\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    return mlp\n",
    "\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    overall_accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return overall_accuracy\n",
    "\n",
    "def cross_validate_six(neuron_arch):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 6, random_state=2)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = labels.loc[train_index], labels.loc[test_index]\n",
    "       \n",
    "        model = train_nn(neuron_arch, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "    return fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_three_neurons = [\n",
    "    (10, 10, 10),\n",
    "    (64, 64, 64),\n",
    "    (128, 128, 128)\n",
    "]\n",
    "\n",
    "nn_three_accuracies = []\n",
    "\n",
    "for n in nn_three_neurons:\n",
    "    nn_accuracies = cross_validate_six(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_three_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Three Hidden Layers\")\n",
    "\n",
    "x = [i[0] for i in nn_three_neurons]\n",
    "plt.plot(x, nn_three_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_three_accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
