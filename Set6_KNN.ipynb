{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dc_listings = pd.read_csv('dc_airbnb.csv')\n",
    "print(dc_listings.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "our_acc_value = 3\n",
    "first_living_space_value = dc_listings.iloc[0]['accommodates']\n",
    "first_distance = np.abs(first_living_space_value - our_acc_value)\n",
    "print(first_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_listing = 3\n",
    "dc_listings['distance'] = dc_listings['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "print(dc_listings['distance'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "dc_listings = dc_listings.sort_values('distance')\n",
    "print(dc_listings.iloc[0:10]['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "mean_price = dc_listings.iloc[0:5]['price'].mean()\n",
    "print(mean_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brought along the changes we made to the `dc_listings` Dataframe.\n",
    "dc_listings = pd.read_csv('dc_airbnb.csv')\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "\n",
    "def predict_price(new_listing):\n",
    "    temp_df = dc_listings.copy()\n",
    "    ## Complete the function.\n",
    "    return(new_listing)\n",
    "\n",
    "acc_one = predict_price(1)\n",
    "acc_two = predict_price(2)\n",
    "acc_four = predict_price(4)\n",
    "def predict_price(new_listing):\n",
    "    temp_df = dc_listings.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbors = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbors.mean()\n",
    "    return(predicted_price)\n",
    "\n",
    "acc_one = predict_price(1)\n",
    "acc_two = predict_price(2)\n",
    "acc_four = predict_price(4)\n",
    "print(acc_one)\n",
    "print(acc_two)\n",
    "print(acc_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings = pd.read_csv(\"dc_airbnb.csv\")\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "train_df = dc_listings.iloc[0:2792]\n",
    "test_df = dc_listings.iloc[2792:]\n",
    "\n",
    "def predict_price(new_listing):\n",
    "    ## DataFrame.copy() performs a deep copy\n",
    "    temp_df = dc_listings.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbor_prices.mean()\n",
    "    return(predicted_price)\n",
    "def predict_price(new_listing):\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbor_prices.mean()\n",
    "    return(predicted_price)\n",
    "\n",
    "test_df['predicted_price'] = test_df['accommodates'].apply(predict_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['error'] = np.absolute(test_df['predicted_price'] - test_df['price'])\n",
    "mae = test_df['error'].mean()\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)\n",
    "mse = test_df['squared_error'].mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dc_listings.iloc[0:2792]\n",
    "test_df = dc_listings.iloc[2792:]\n",
    "\n",
    "def predict_price(new_listing):\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbors_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbors_prices.mean()\n",
    "    return(predicted_price)\n",
    "def predict_price(new_listing):\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['bathrooms'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbors_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbors_prices.mean()\n",
    "    return(predicted_price)\n",
    "\n",
    "test_df['predicted_price'] = test_df['bathrooms'].apply(lambda x: predict_price(x))\n",
    "test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)\n",
    "mse = test_df['squared_error'].mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(new_listing):\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['bathrooms'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbors_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbors_prices.mean()\n",
    "    return(predicted_price)\n",
    "\n",
    "test_df['predicted_price'] = test_df['bathrooms'].apply(lambda x: predict_price(x))\n",
    "test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)\n",
    "mse = test_df['squared_error'].mean()\n",
    "rmse = mse ** (1/2)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_one = pd.Series([5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10])\n",
    "errors_two = pd.Series([5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 10, 5, 1000])\n",
    "mae_one = errors_one.sum()/len(errors_one)\n",
    "rmse_one = np.sqrt((errors_one**2).sum()/len(errors_one))\n",
    "print(mae_one)\n",
    "print(rmse_one)\n",
    "\n",
    "mae_two = errors_two.sum()/len(errors_two)\n",
    "rmse_two = np.sqrt((errors_two**2).sum()/len(errors_two))\n",
    "print(mae_two)\n",
    "print(rmse_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings = pd.read_csv('dc_airbnb.csv')\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "print(dc_listings.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['room_type', 'city', 'state', 'latitude', 'longitude', 'zipcode', 'host_response_rate', 'host_acceptance_rate', 'host_listings_count']\n",
    "dc_listings = dc_listings.drop(drop_columns, axis=1)\n",
    "print(dc_listings.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings = dc_listings.drop(['cleaning_fee', 'security_deposit'], axis=1)\n",
    "dc_listings = dc_listings.dropna(axis=0)\n",
    "print(dc_listings.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_listings = (dc_listings - dc_listings.mean())/(dc_listings.std())\n",
    "normalized_listings['price'] = dc_listings['price']\n",
    "print(normalized_listings.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "first_listing = normalized_listings.iloc[0][['accommodates', 'bathrooms']]\n",
    "fifth_listing = normalized_listings.iloc[4][['accommodates', 'bathrooms']]\n",
    "first_fifth_distance = distance.euclidean(first_listing, fifth_listing)\n",
    "print(first_fifth_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "train_columns = ['accommodates', 'bathrooms']\n",
    "\n",
    "# Instantiate ML model.\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "\n",
    "# Fit model to data.\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "\n",
    "# Use model to make predictions.\n",
    "predictions = knn.predict(test_df[train_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_columns = ['accommodates', 'bathrooms']\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute', metric='euclidean')\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "predictions = knn.predict(test_df[train_columns])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "two_features_mse = mean_squared_error(test_df['price'], predictions)\n",
    "two_features_rmse = two_features_mse ** (1/2)\n",
    "print(two_features_mse)\n",
    "print(two_features_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "knn.fit(train_df[features], train_df['price'])\n",
    "four_predictions = knn.predict(test_df[features])\n",
    "four_mse = mean_squared_error(test_df['price'], four_predictions)\n",
    "four_rmse = four_mse ** (1/2)\n",
    "print(four_mse)\n",
    "print(four_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "\n",
    "features = train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "\n",
    "knn.fit(train_df[features], train_df['price'])\n",
    "all_features_predictions = knn.predict(test_df[features])\n",
    "all_features_mse = mean_squared_error(test_df['price'], all_features_predictions)\n",
    "all_features_rmse = all_features_mse ** (1/2)\n",
    "print(all_features_mse)\n",
    "print(all_features_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dc_airbnb_train.csv')\n",
    "test_df = pd.read_csv('dc_airbnb_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "hyper_params = [1, 2, 3, 4, 5]\n",
    "mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "print(mse_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "hyper_params = [x for x in range(1, 21)]\n",
    "mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "print(mse_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "hyper_params = [x for x in range(1, 21)]\n",
    "mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "plt.scatter(hyper_params, mse_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = [x for x in range(1,21)]\n",
    "mse_values = list()\n",
    "features = train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "plt.scatter(hyper_params, mse_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_features = ['accommodates', 'bathrooms']\n",
    "three_features = ['accommodates', 'bathrooms', 'bedrooms']\n",
    "hyper_params = [x for x in range(1,21)]\n",
    "# Append the first model's MSE values to this list.\n",
    "two_mse_values = list()\n",
    "# Append the second model's MSE values to this list.\n",
    "three_mse_values = list()\n",
    "two_hyp_mse = dict()\n",
    "three_hyp_mse = dict()\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[two_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[two_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    two_mse_values.append(mse)\n",
    "\n",
    "two_lowest_mse = two_mse_values[0]\n",
    "two_lowest_k = 1\n",
    "\n",
    "for k,mse in enumerate(two_mse_values):\n",
    "    if mse < two_lowest_mse:\n",
    "        two_lowest_mse = mse\n",
    "        two_lowest_k = k + 1\n",
    "    \n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[three_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[three_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    three_mse_values.append(mse)\n",
    "    \n",
    "three_lowest_mse = three_mse_values[0]\n",
    "three_lowest_k = 1\n",
    "\n",
    "for k,mse in enumerate(three_mse_values):\n",
    "    if mse < three_lowest_mse:\n",
    "        three_lowest_mse = mse\n",
    "        three_lowest_k = k + 1\n",
    "\n",
    "two_hyp_mse[two_lowest_k] = two_lowest_mse\n",
    "three_hyp_mse[three_lowest_k] = three_lowest_mse\n",
    "\n",
    "print(two_hyp_mse)\n",
    "print(three_hyp_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings = pd.read_csv(\"dc_airbnb.csv\")\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "shuffled_index = np.random.permutation(dc_listings.index)\n",
    "dc_listings = dc_listings.reindex(shuffled_index)\n",
    "\n",
    "split_one = dc_listings.iloc[0:1862].copy()\n",
    "split_two = dc_listings.iloc[1862:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_one = split_one\n",
    "test_one = split_two\n",
    "train_two = split_two\n",
    "test_two = split_one\n",
    "# First half\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(train_one[[\"accommodates\"]], train_one[\"price\"])\n",
    "test_one[\"predicted_price\"] = model.predict(test_one[[\"accommodates\"]])\n",
    "iteration_one_rmse = mean_squared_error(test_one[\"price\"], test_one[\"predicted_price\"])**(1/2)\n",
    "\n",
    "# Second half\n",
    "model.fit(train_two[[\"accommodates\"]], train_two[\"price\"])\n",
    "test_two[\"predicted_price\"] = model.predict(test_two[[\"accommodates\"]])\n",
    "iteration_two_rmse = mean_squared_error(test_two[\"price\"], test_two[\"predicted_price\"])**(1/2)\n",
    "\n",
    "avg_rmse = np.mean([iteration_two_rmse, iteration_one_rmse])\n",
    "\n",
    "print(iteration_one_rmse, iteration_two_rmse, avg_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_listings.loc[dc_listings.index[0:745], \"fold\"] = 1\n",
    "dc_listings.loc[dc_listings.index[745:1490], \"fold\"] = 2\n",
    "dc_listings.loc[dc_listings.index[1490:2234], \"fold\"] = 3\n",
    "dc_listings.loc[dc_listings.index[2234:2978], \"fold\"] = 4\n",
    "dc_listings.loc[dc_listings.index[2978:3723], \"fold\"] = 5\n",
    "\n",
    "print(dc_listings['fold'].value_counts())\n",
    "print(\"\\n Num of missing values: \", dc_listings['fold'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Training\n",
    "model = KNeighborsRegressor()\n",
    "train_iteration_one = dc_listings[dc_listings[\"fold\"] != 1]\n",
    "test_iteration_one = dc_listings[dc_listings[\"fold\"] == 1].copy()\n",
    "model.fit(train_iteration_one[[\"accommodates\"]], train_iteration_one[\"price\"])\n",
    "\n",
    "# Predicting\n",
    "labels = model.predict(test_iteration_one[[\"accommodates\"]])\n",
    "test_iteration_one[\"predicted_price\"] = labels\n",
    "iteration_one_mse = mean_squared_error(test_iteration_one[\"price\"], test_iteration_one[\"predicted_price\"])\n",
    "iteration_one_rmse = iteration_one_mse ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.mean to calculate the mean.\n",
    "import numpy as np\n",
    "fold_ids = [1,2,3,4,5]\n",
    "def train_and_validate(df, folds):\n",
    "    fold_rmses = []\n",
    "    for fold in folds:\n",
    "        # Train\n",
    "        model = KNeighborsRegressor()\n",
    "        train = df[df[\"fold\"] != fold]\n",
    "        test = df[df[\"fold\"] == fold].copy()\n",
    "        model.fit(train[[\"accommodates\"]], train[\"price\"])\n",
    "        # Predict\n",
    "        labels = model.predict(test[[\"accommodates\"]])\n",
    "        test[\"predicted_price\"] = labels\n",
    "        mse = mean_squared_error(test[\"price\"], test[\"predicted_price\"])\n",
    "        rmse = mse**(1/2)\n",
    "        fold_rmses.append(rmse)\n",
    "    return(fold_rmses)\n",
    "\n",
    "rmses = train_and_validate(dc_listings, fold_ids)\n",
    "print(rmses)\n",
    "avg_rmse = np.mean(rmses)\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kf = KFold(5, shuffle=True, random_state=1)\n",
    "model = KNeighborsRegressor()\n",
    "mses = cross_val_score(model, dc_listings[[\"accommodates\"]], dc_listings[\"price\"], scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "rmses = np.sqrt(np.absolute(mses))\n",
    "avg_rmse = np.mean(rmses)\n",
    "\n",
    "print(rmses)\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', \n",
    "        'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type', \n",
    "        'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-rate', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "cars = pd.read_csv('imports-85.data', names=cols)\n",
    "\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns with continuous values from - https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.names\n",
    "continuous_values_cols = ['normalized-losses', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'bore', 'stroke', 'compression-rate', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "numeric_cars = cars[continuous_values_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cars.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cars = numeric_cars.replace('?', np.nan)\n",
    "numeric_cars.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cars = numeric_cars.astype('float')\n",
    "numeric_cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because `price` is the column we want to predict, let's remove any rows with missing `price` values.\n",
    "numeric_cars = numeric_cars.dropna(subset=['price'])\n",
    "numeric_cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in other columns using column means.\n",
    "numeric_cars = numeric_cars.fillna(numeric_cars.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that there's no more missing values!\n",
    "numeric_cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all columnns to range from 0 to 1 except the target column.\n",
    "price_col = numeric_cars['price']\n",
    "numeric_cars = (numeric_cars - numeric_cars.min())/(numeric_cars.max() - numeric_cars.min())\n",
    "numeric_cars['price'] = price_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def knn_train_test(train_col, target_col, df):\n",
    "    knn = KNeighborsRegressor()\n",
    "    np.random.seed(1)\n",
    "        \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    rand_df = df.reindex(shuffled_index)\n",
    "\n",
    "    # Divide number of rows in half and round.\n",
    "    last_train_row = int(len(rand_df) / 2)\n",
    "    \n",
    "    # Select the first half and set as training set.\n",
    "    # Select the second half and set as test set.\n",
    "    train_df = rand_df.iloc[0:last_train_row]\n",
    "    test_df = rand_df.iloc[last_train_row:]\n",
    "    \n",
    "    # Fit a KNN model using default k value.\n",
    "    knn.fit(train_df[[train_col]], train_df[target_col])\n",
    "    \n",
    "    # Make predictions using model.\n",
    "    predicted_labels = knn.predict(test_df[[train_col]])\n",
    "\n",
    "    # Calculate and return RMSE.\n",
    "    mse = mean_squared_error(test_df[target_col], predicted_labels)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "rmse_results = {}\n",
    "train_cols = numeric_cars.columns.drop('price')\n",
    "\n",
    "# For each column (minus `price`), train a model, return RMSE value\n",
    "# and add to the dictionary `rmse_results`.\n",
    "for col in train_cols:\n",
    "    rmse_val = knn_train_test(col, 'price', numeric_cars)\n",
    "    rmse_results[col] = rmse_val\n",
    "\n",
    "# Create a Series object from the dictionary so \n",
    "# we can easily view the results, sort, etc\n",
    "rmse_results_series = pd.Series(rmse_results)\n",
    "rmse_results_series.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train_test(train_col, target_col, df):\n",
    "    np.random.seed(1)\n",
    "        \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    rand_df = df.reindex(shuffled_index)\n",
    "\n",
    "    # Divide number of rows in half and round.\n",
    "    last_train_row = int(len(rand_df) / 2)\n",
    "    \n",
    "    # Select the first half and set as training set.\n",
    "    # Select the second half and set as test set.\n",
    "    train_df = rand_df.iloc[0:last_train_row]\n",
    "    test_df = rand_df.iloc[last_train_row:]\n",
    "    \n",
    "    k_values = [1,3,5,7,9]\n",
    "    k_rmses = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Fit model using k nearest neighbors.\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        knn.fit(train_df[[train_col]], train_df[target_col])\n",
    "\n",
    "        # Make predictions using model.\n",
    "        predicted_labels = knn.predict(test_df[[train_col]])\n",
    "\n",
    "        # Calculate and return RMSE.\n",
    "        mse = mean_squared_error(test_df[target_col], predicted_labels)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        k_rmses[k] = rmse\n",
    "    return k_rmses\n",
    "\n",
    "k_rmse_results = {}\n",
    "\n",
    "# For each column (minus `price`), train a model, return RMSE value\n",
    "# and add to the dictionary `rmse_results`.\n",
    "train_cols = numeric_cars.columns.drop('price')\n",
    "for col in train_cols:\n",
    "    rmse_val = knn_train_test(col, 'price', numeric_cars)\n",
    "    k_rmse_results[col] = rmse_val\n",
    "\n",
    "k_rmse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for k,v in k_rmse_results.items():\n",
    "    x = list(v.keys())\n",
    "    y = list(v.values())\n",
    "    \n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('k value')\n",
    "    plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average RMSE across different `k` values for each feature.\n",
    "feature_avg_rmse = {}\n",
    "for k,v in k_rmse_results.items():\n",
    "    avg_rmse = np.mean(list(v.values()))\n",
    "    feature_avg_rmse[k] = avg_rmse\n",
    "series_avg_rmse = pd.Series(feature_avg_rmse)\n",
    "sorted_series_avg_rmse = series_avg_rmse.sort_values()\n",
    "print(sorted_series_avg_rmse)\n",
    "\n",
    "sorted_features = sorted_series_avg_rmse.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train_test(train_cols, target_col, df):\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    rand_df = df.reindex(shuffled_index)\n",
    "\n",
    "    # Divide number of rows in half and round.\n",
    "    last_train_row = int(len(rand_df) / 2)\n",
    "    \n",
    "    # Select the first half and set as training set.\n",
    "    # Select the second half and set as test set.\n",
    "    train_df = rand_df.iloc[0:last_train_row]\n",
    "    test_df = rand_df.iloc[last_train_row:]\n",
    "    \n",
    "    k_values = [5]\n",
    "    k_rmses = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Fit model using k nearest neighbors.\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        knn.fit(train_df[train_cols], train_df[target_col])\n",
    "\n",
    "        # Make predictions using model.\n",
    "        predicted_labels = knn.predict(test_df[train_cols])\n",
    "\n",
    "        # Calculate and return RMSE.\n",
    "        mse = mean_squared_error(test_df[target_col], predicted_labels)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        k_rmses[k] = rmse\n",
    "    return k_rmses\n",
    "\n",
    "k_rmse_results = {}\n",
    "\n",
    "for nr_best_feats in range(2,7):\n",
    "    k_rmse_results['{} best features'.format(nr_best_feats)] = knn_train_test(\n",
    "        sorted_features[:nr_best_feats],\n",
    "        'price',\n",
    "        numeric_cars\n",
    "    )\n",
    "\n",
    "k_rmse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_train_test(train_cols, target_col, df):\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Randomize order of rows in data frame.\n",
    "    shuffled_index = np.random.permutation(df.index)\n",
    "    rand_df = df.reindex(shuffled_index)\n",
    "\n",
    "    # Divide number of rows in half and round.\n",
    "    last_train_row = int(len(rand_df) / 2)\n",
    "    \n",
    "    # Select the first half and set as training set.\n",
    "    # Select the second half and set as test set.\n",
    "    train_df = rand_df.iloc[0:last_train_row]\n",
    "    test_df = rand_df.iloc[last_train_row:]\n",
    "    \n",
    "    k_values = [i for i in range(1, 25)]\n",
    "    k_rmses = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Fit model using k nearest neighbors.\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        knn.fit(train_df[train_cols], train_df[target_col])\n",
    "\n",
    "        # Make predictions using model.\n",
    "        predicted_labels = knn.predict(test_df[train_cols])\n",
    "\n",
    "        # Calculate and return RMSE.\n",
    "        mse = mean_squared_error(test_df[target_col], predicted_labels)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        k_rmses[k] = rmse\n",
    "    return k_rmses\n",
    "\n",
    "k_rmse_results = {}\n",
    "\n",
    "for nr_best_feats in range(2,6):\n",
    "    k_rmse_results['{} best features'.format(nr_best_feats)] = knn_train_test(\n",
    "        sorted_features[:nr_best_feats],\n",
    "        'price',\n",
    "        numeric_cars\n",
    "    )\n",
    "\n",
    "k_rmse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in k_rmse_results.items():\n",
    "    x = list(v.keys())\n",
    "    y = list(v.values())  \n",
    "    plt.plot(x,y, label=\"{}\".format(k))\n",
    "    \n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
