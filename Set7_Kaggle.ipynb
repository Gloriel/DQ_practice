{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_shape = test.shape\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train_shape = train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sex_pivot = train.pivot_table(index=\"Sex\",values=\"Survived\")\n",
    "sex_pivot.plot.bar()\n",
    "plt.show()\n",
    "class_pivot = train.pivot_table(index=\"Pclass\",values=\"Survived\")\n",
    "class_pivot.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_age(df,cut_points,label_names):\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "cut_points = [-1,0,5,12,18,35,60,100]\n",
    "label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n",
    "\n",
    "train = process_age(train,cut_points,label_names)\n",
    "test = process_age(test,cut_points,label_names)\n",
    "\n",
    "pivot = train.pivot_table(index=\"Age_categories\",values='Survived')\n",
    "pivot.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df,column_name):\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df\n",
    "\n",
    "train = create_dummies(train,\"Pclass\")\n",
    "test = create_dummies(test,\"Pclass\")\n",
    "train = create_dummies(train,\"Sex\")\n",
    "test = create_dummies(test,\"Sex\")\n",
    "\n",
    "train = create_dummies(train,\"Age_categories\")\n",
    "test = create_dummies(test,\"Age_categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
    "       'Age_categories_Missing','Age_categories_Infant',\n",
    "       'Age_categories_Child', 'Age_categories_Teenager',\n",
    "       'Age_categories_Young Adult', 'Age_categories_Adult',\n",
    "       'Age_categories_Senior']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train[columns], train[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = test # from now on we will refer to this\n",
    "               # dataframe as the holdout data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "columns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
    "       'Age_categories_Missing','Age_categories_Infant',\n",
    "       'Age_categories_Child', 'Age_categories_Teenager',\n",
    "       'Age_categories_Young Adult', 'Age_categories_Adult',\n",
    "       'Age_categories_Senior']\n",
    "all_X = train[columns]\n",
    "all_y = train['Survived']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    all_X, all_y, test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_X, train_y)\n",
    "predictions = lr.predict(test_X)\n",
    "accuracy = accuracy_score(test_y, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "lr = LogisticRegression()\n",
    "scores = cross_val_score(lr, all_X, all_y, cv=10)\n",
    "accuracy = np.mean(scores)\n",
    "print(scores)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
    "       'Age_categories_Missing','Age_categories_Infant',\n",
    "       'Age_categories_Child', 'Age_categories_Teenager',\n",
    "       'Age_categories_Young Adult', 'Age_categories_Adult',\n",
    "       'Age_categories_Senior']\n",
    "lr = LogisticRegression()\n",
    "lr.fit(all_X,all_y)\n",
    "holdout_predictions = lr.predict(holdout[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "holdout = pd.read_csv('test.csv')\n",
    "\n",
    "def process_age(df):\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n",
    "    cut_points = [-1,0,5,12,18,35,60,100]\n",
    "    label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def create_dummies(df,column_name):\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df\n",
    "train = process_age(train)\n",
    "holdout = process_age(holdout)\n",
    "\n",
    "for column in [\"Age_categories\",\"Pclass\",\"Sex\"]:\n",
    "    train = create_dummies(train,column)\n",
    "    holdout = create_dummies(holdout,column)\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "# The holdout set has a missing value in the Fare column which\n",
    "# we'll fill with the mean.\n",
    "holdout[\"Fare\"] = holdout[\"Fare\"].fillna(train[\"Fare\"].mean())\n",
    "columns = [\"SibSp\",\"Parch\",\"Fare\"]\n",
    "\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "holdout[\"Embarked\"] = holdout[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "train = create_dummies(train,\"Embarked\")\n",
    "holdout = create_dummies(holdout,\"Embarked\")\n",
    "\n",
    "for col in columns:\n",
    "    train[col + \"_scaled\"] = minmax_scale(train[col])\n",
    "    holdout[col + \"_scaled\"] = minmax_scale(holdout[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "columns = ['Age_categories_Missing', 'Age_categories_Infant',\n",
    "       'Age_categories_Child', 'Age_categories_Teenager',\n",
    "       'Age_categories_Young Adult', 'Age_categories_Adult',\n",
    "       'Age_categories_Senior', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
    "       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
    "       'SibSp_scaled', 'Parch_scaled', 'Fare_scaled']\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train[columns],train['Survived'])\n",
    "\n",
    "coefficients = lr.coef_\n",
    "\n",
    "feature_importance = pd.Series(coefficients[0],\n",
    "                               index=train[columns].columns)\n",
    "feature_importance.plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "columns = ['Age_categories_Infant', 'SibSp_scaled', 'Sex_female', 'Sex_male',\n",
    "       'Pclass_1', 'Pclass_3', 'Age_categories_Senior', 'Parch_scaled']\n",
    "all_X = train[columns]\n",
    "all_y = train['Survived']\n",
    "\n",
    "lr = LogisticRegression()\n",
    "scores = cross_val_score(lr, all_X, all_y, cv=10)\n",
    "accuracy = scores.mean()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Age_categories_Infant', 'SibSp_scaled', 'Sex_female', 'Sex_male',\n",
    "       'Pclass_1', 'Pclass_3', 'Age_categories_Senior', 'Parch_scaled']\n",
    "\n",
    "all_X = train[columns]\n",
    "all_y = train['Survived']\n",
    "lr = LogisticRegression()\n",
    "lr.fit(all_X,all_y)\n",
    "holdout_predictions = lr.predict(holdout[columns])\n",
    "\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"submission_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_age(df,cut_points,label_names):\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "def process_fare(df,cut_points,label_names):\n",
    "    df[\"Fare_categories\"] = pd.cut(df[\"Fare\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "cut_points = [0,12,50,100,1000]\n",
    "label_names = [\"0-12\",\"12-50\",\"50-100\",\"100+\"]\n",
    "\n",
    "train = process_fare(train,cut_points,label_names)\n",
    "holdout = process_fare(holdout,cut_points,label_names)\n",
    "\n",
    "train = create_dummies(train,\"Fare_categories\")\n",
    "holdout = create_dummies(holdout,\"Fare_categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {\n",
    "    \"Mr\" :         \"Mr\",\n",
    "    \"Mme\":         \"Mrs\",\n",
    "    \"Ms\":          \"Mrs\",\n",
    "    \"Mrs\" :        \"Mrs\",\n",
    "    \"Master\" :     \"Master\",\n",
    "    \"Mlle\":        \"Miss\",\n",
    "    \"Miss\" :       \"Miss\",\n",
    "    \"Capt\":        \"Officer\",\n",
    "    \"Col\":         \"Officer\",\n",
    "    \"Major\":       \"Officer\",\n",
    "    \"Dr\":          \"Officer\",\n",
    "    \"Rev\":         \"Officer\",\n",
    "    \"Jonkheer\":    \"Royalty\",\n",
    "    \"Don\":         \"Royalty\",\n",
    "    \"Sir\" :        \"Royalty\",\n",
    "    \"Countess\":    \"Royalty\",\n",
    "    \"Dona\":        \"Royalty\",\n",
    "    \"Lady\" :       \"Royalty\"\n",
    "}\n",
    "\n",
    "extracted_titles = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "train[\"Title\"] = extracted_titles.map(titles)\n",
    "extracted_titles = holdout[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "holdout[\"Title\"] = extracted_titles.map(titles)\n",
    "\n",
    "train[\"Cabin_type\"] = train[\"Cabin\"].str[0]\n",
    "train[\"Cabin_type\"] = train[\"Cabin_type\"].fillna(\"Unknown\")\n",
    "\n",
    "holdout[\"Cabin_type\"] = holdout[\"Cabin\"].str[0]\n",
    "holdout[\"Cabin_type\"] = holdout[\"Cabin_type\"].fillna(\"Unknown\")\n",
    "\n",
    "for column in [\"Title\",\"Cabin_type\"]:\n",
    "    train = create_dummies(train,column)\n",
    "    holdout = create_dummies(holdout,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_correlation_heatmap(df):\n",
    "    corr = df.corr()\n",
    "    \n",
    "    sns.set(style=\"white\")\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    plt.show()\n",
    "\n",
    "columns = ['Age_categories_Missing', 'Age_categories_Infant',\n",
    "       'Age_categories_Child', 'Age_categories_Teenager',\n",
    "       'Age_categories_Young Adult', 'Age_categories_Adult',\n",
    "       'Age_categories_Senior', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
    "       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
    "       'SibSp_scaled', 'Parch_scaled', 'Fare_categories_0-12',\n",
    "       'Fare_categories_12-50','Fare_categories_50-100', 'Fare_categories_100+',\n",
    "       'Title_Master', 'Title_Miss', 'Title_Mr','Title_Mrs', 'Title_Officer',\n",
    "       'Title_Royalty', 'Cabin_type_A','Cabin_type_B', 'Cabin_type_C', 'Cabin_type_D',\n",
    "       'Cabin_type_E','Cabin_type_F', 'Cabin_type_G', 'Cabin_type_T', 'Cabin_type_Unknown']\n",
    "plot_correlation_heatmap(train[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "columns = ['Age_categories_Missing', 'Age_categories_Infant',\n",
    "       'Age_categories_Child', 'Age_categories_Young Adult',\n",
    "       'Age_categories_Adult', 'Age_categories_Senior', 'Pclass_1', 'Pclass_3',\n",
    "       'Embarked_C', 'Embarked_Q', 'Embarked_S', 'SibSp_scaled',\n",
    "       'Parch_scaled', 'Fare_categories_0-12', 'Fare_categories_50-100',\n",
    "       'Fare_categories_100+', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n",
    "       'Title_Officer', 'Title_Royalty', 'Cabin_type_B', 'Cabin_type_C',\n",
    "       'Cabin_type_D', 'Cabin_type_E', 'Cabin_type_F', 'Cabin_type_G',\n",
    "       'Cabin_type_T', 'Cabin_type_Unknown']\n",
    "\n",
    "all_X = train[columns]\n",
    "all_y = train[\"Survived\"]\n",
    "lr = LogisticRegression()\n",
    "selector = RFECV(lr,cv=10)\n",
    "selector.fit(all_X,all_y)\n",
    "\n",
    "optimized_columns = all_X.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = train[optimized_columns]\n",
    "all_y = train[\"Survived\"]\n",
    "lr = LogisticRegression()\n",
    "scores = cross_val_score(lr, all_X, all_y, cv=10)\n",
    "accuracy = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(all_X,all_y)\n",
    "holdout_predictions = lr.predict(holdout[optimized_columns])\n",
    "\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"submission_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train_modified.csv')\n",
    "holdout = pd.read_csv('holdout_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "all_X = train.drop(['Survived','PassengerId'],axis=1)\n",
    "all_y = train['Survived']\n",
    "lr = LogisticRegression()\n",
    "scores = cross_val_score(lr, all_X, all_y, cv=10)\n",
    "accuracy_lr = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "scores = cross_val_score(knn, all_X, all_y, cv=10)\n",
    "accuracy_knn = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_dict(dictionary):\n",
    "    pd.Series(dictionary).plot.bar(figsize=(9,6),\n",
    "                                   ylim=(0.78,0.83),rot=0)\n",
    "    plt.show()\n",
    "\n",
    "knn_scores = dict()\n",
    "for k in range(1,50,2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    scores = cross_val_score(knn, all_X, all_y, cv=10)\n",
    "    accuracy_knn = scores.mean()\n",
    "    knn_scores[k] = accuracy_knn\n",
    "\n",
    "plot_dict(knn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_neighbors\": range(1,20,2),\n",
    "    \"weights\": [\"distance\", \"uniform\"],\n",
    "    \"algorithm\": ['brute'],\n",
    "    \"p\": [1,2]\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn,param_grid=hyperparameters,cv=10)\n",
    "\n",
    "grid.fit(all_X, all_y)\n",
    "\n",
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_no_id = holdout.drop(['PassengerId'],axis=1)\n",
    "best_knn = grid.best_estimator_\n",
    "holdout_predictions = best_knn.predict(holdout_no_id)\n",
    "\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"submission_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=1)\n",
    "scores = cross_val_score(clf, all_X, all_y, cv=10)\n",
    "accuracy_rf = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"criterion\": [\"entropy\", \"gini\"],\n",
    "                   \"max_depth\": [5, 10],\n",
    "                   \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                   \"min_samples_leaf\": [1, 5],\n",
    "                   \"min_samples_split\": [3, 5],\n",
    "                   \"n_estimators\": [6, 9]\n",
    "}\n",
    "\n",
    "clf = RandomForestClassifier(random_state=1)\n",
    "grid = GridSearchCV(clf,param_grid=hyperparameters,cv=10)\n",
    "\n",
    "grid.fit(all_X, all_y)\n",
    "\n",
    "best_params = grid.best_params_\n",
    "best_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `GridSearchCV` object is stored in memory from\n",
    "# the previous screen with the variable name `grid`\n",
    "best_rf = grid.best_estimator_\n",
    "holdout_predictions = best_rf.predict(holdout_no_id)\n",
    "\n",
    "holdout_ids = holdout[\"PassengerId\"]\n",
    "submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": holdout_predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "\n",
    "submission.to_csv(\"submission_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "holdout = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load functions.py\n",
    "def process_missing(df):\n",
    "    \"\"\"Handle various missing values from the data set\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    holdout = process_missing(holdout)\n",
    "    \"\"\"\n",
    "    df[\"Fare\"] = df[\"Fare\"].fillna(train[\"Fare\"].mean())\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "    return df\n",
    "\n",
    "def process_age(df):\n",
    "    \"\"\"Process the Age column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_age(train)\n",
    "    \"\"\"\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n",
    "    cut_points = [-1,0,5,12,18,35,60,100]\n",
    "    label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def process_fare(df):\n",
    "    \"\"\"Process the Fare column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_fare(train)\n",
    "    \"\"\"\n",
    "    cut_points = [-1,12,50,100,1000]\n",
    "    label_names = [\"0-12\",\"12-50\",\"50-100\",\"100+\"]\n",
    "    df[\"Fare_categories\"] = pd.cut(df[\"Fare\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def process_cabin(df):\n",
    "    \"\"\"Process the Cabin column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train process_cabin(train)\n",
    "    \"\"\"\n",
    "    df[\"Cabin_type\"] = df[\"Cabin\"].str[0]\n",
    "    df[\"Cabin_type\"] = df[\"Cabin_type\"].fillna(\"Unknown\")\n",
    "    df = df.drop('Cabin',axis=1)\n",
    "    return df\n",
    "\n",
    "def process_titles(df):\n",
    "    \"\"\"Extract and categorize the title from the name column \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_titles(train)\n",
    "    \"\"\"\n",
    "    titles = {\n",
    "        \"Mr\" :         \"Mr\",\n",
    "        \"Mme\":         \"Mrs\",\n",
    "        \"Ms\":          \"Mrs\",\n",
    "        \"Mrs\" :        \"Mrs\",\n",
    "        \"Master\" :     \"Master\",\n",
    "        \"Mlle\":        \"Miss\",\n",
    "        \"Miss\" :       \"Miss\",\n",
    "        \"Capt\":        \"Officer\",\n",
    "        \"Col\":         \"Officer\",\n",
    "        \"Major\":       \"Officer\",\n",
    "        \"Dr\":          \"Officer\",\n",
    "        \"Rev\":         \"Officer\",\n",
    "        \"Jonkheer\":    \"Royalty\",\n",
    "        \"Don\":         \"Royalty\",\n",
    "        \"Sir\" :        \"Royalty\",\n",
    "        \"Countess\":    \"Royalty\",\n",
    "        \"Dona\":        \"Royalty\",\n",
    "        \"Lady\" :       \"Royalty\"\n",
    "    }\n",
    "    extracted_titles = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "    df[\"Title\"] = extracted_titles.map(titles)\n",
    "    return df\n",
    "\n",
    "def create_dummies(df,column_name):\n",
    "    \"\"\"Create Dummy Columns (One Hot Encoding) from a single Column\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = create_dummies(train,\"Age\")\n",
    "    \"\"\"\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    df = process_missing(df)\n",
    "    df = process_age(df)\n",
    "    df = process_fare(df)\n",
    "    df = process_titles(df)\n",
    "    df = process_cabin(df)\n",
    "\n",
    "    for col in [\"Age_categories\",\"Fare_categories\",\n",
    "                \"Title\",\"Cabin_type\",\"Sex\"]:\n",
    "        df = create_dummies(df,col)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = pre_process(train)\n",
    "holdout = pre_process(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_cols = [\"SibSp\",\"Parch\",\"Survived\"]\n",
    "explore = train[explore_cols].copy()\n",
    "explore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "explore.drop(\"Survived\",axis=1).plot.hist(alpha=0.5,bins=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore[\"familysize\"] = explore[[\"SibSp\",\"Parch\"]].sum(axis=1)\n",
    "explore.drop(\"Survived\",axis=1).plot.hist(alpha=0.5,bins=10)\n",
    "plt.xticks(range(11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for col in explore.columns.drop(\"Survived\"):\n",
    "    pivot = explore.pivot_table(index=col,values=\"Survived\")\n",
    "    pivot.plot.bar(ylim=(0,1),yticks=np.arange(0,1,.1))\n",
    "    plt.axhspan(.3, .6, alpha=0.2, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_isalone(df):\n",
    "    df[\"familysize\"] = df[[\"SibSp\",\"Parch\"]].sum(axis=1)\n",
    "    df[\"isalone\"] = 0\n",
    "    df.loc[(df[\"familysize\"] == 0),\"isalone\"] = 1\n",
    "    df = df.drop(\"familysize\",axis=1)\n",
    "    return df\n",
    "\n",
    "train = process_isalone(train)\n",
    "holdout = process_isalone(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def select_features(df):\n",
    "    # Remove non-numeric columns, columns that have null values\n",
    "    df = df.select_dtypes([np.number]).dropna(axis=1)\n",
    "    all_X = df.drop([\"Survived\",\"PassengerId\"],axis=1)\n",
    "    all_y = df[\"Survived\"]\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=1)\n",
    "    selector = RFECV(clf,cv=10)\n",
    "    selector.fit(all_X,all_y)\n",
    "    \n",
    "    best_columns = list(all_X.columns[selector.support_])\n",
    "    print(\"Best Columns \\n\"+\"-\"*12+\"\\n{}\\n\".format(best_columns))\n",
    "    \n",
    "    return best_columns\n",
    "\n",
    "cols = select_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def select_model(df,features):\n",
    "    \n",
    "    all_X = df[features]\n",
    "    all_y = df[\"Survived\"]\n",
    "\n",
    "    # List of dictionaries, each containing a model name,\n",
    "    # it's estimator and a dict of hyperparameters\n",
    "    models = [\n",
    "        {\n",
    "            \"name\": \"LogisticRegression\",\n",
    "            \"estimator\": LogisticRegression(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"KNeighborsClassifier\",\n",
    "            \"estimator\": KNeighborsClassifier(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"n_neighbors\": range(1,20,2),\n",
    "                    \"weights\": [\"distance\", \"uniform\"],\n",
    "                    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                    \"p\": [1,2]\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"RandomForestClassifier\",\n",
    "            \"estimator\": RandomForestClassifier(random_state=1),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"n_estimators\": [4, 6, 9],\n",
    "                    \"criterion\": [\"entropy\", \"gini\"],\n",
    "                    \"max_depth\": [2, 5, 10],\n",
    "                    \"max_features\": [\"log2\", \"sqrt\"],\n",
    "                    \"min_samples_leaf\": [1, 5, 8],\n",
    "                    \"min_samples_split\": [2, 3, 5]\n",
    "\n",
    "                }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for model in models:\n",
    "        print(model['name'])\n",
    "        print('-'*len(model['name']))\n",
    "\n",
    "        grid = GridSearchCV(model[\"estimator\"],\n",
    "                            param_grid=model[\"hyperparameters\"],\n",
    "                            cv=10)\n",
    "        grid.fit(all_X,all_y)\n",
    "        model[\"best_params\"] = grid.best_params_\n",
    "        model[\"best_score\"] = grid.best_score_\n",
    "        model[\"best_model\"] = grid.best_estimator_\n",
    "\n",
    "        print(\"Best Score: {}\".format(model[\"best_score\"]))\n",
    "        print(\"Best Parameters: {}\\n\".format(model[\"best_params\"]))\n",
    "\n",
    "    return models\n",
    "\n",
    "result = select_model(train,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_file(model,cols,filename=\"submission.csv\"):\n",
    "    holdout_data = holdout[cols]\n",
    "    predictions = model.predict(holdout_data)\n",
    "    \n",
    "    holdout_ids = holdout[\"PassengerId\"]\n",
    "    submission_df = {\"PassengerId\": holdout_ids,\n",
    "                 \"Survived\": predictions}\n",
    "    submission = pd.DataFrame(submission_df)\n",
    "\n",
    "    submission.to_csv(filename,index=False)\n",
    "\n",
    "best_rf_model = result[2][\"best_model\"]\n",
    "save_submission_file(best_rf_model,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
