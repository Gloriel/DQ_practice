{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Data analystds for a company that builds Android and iOS mobile apps. \n",
    "We make our apps available on Google Play and the App Store.\n",
    "\n",
    "We only build apps that are free to download and install, and our main source of revenue consists of in-app ads. \n",
    "\n",
    "This means our revenue for any given app is mostly influenced by the number of users who use our app ‚Äî the more users that see and engage with the ads, the better. \n",
    "\n",
    "Our goal for this project is to analyze data to help our developers understand what type of apps are likely to attract more users.\n",
    "\n",
    "To avoid spending resources on collecting new data ourselves, we should first try to see if we can find any relevant existing data at no cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explore_data() function:\n",
    "\n",
    "Takes in four parameters:\n",
    "dataset, which is expected to be a list of lists.\n",
    "start and end, which are both expected to be integers and represent the starting and the ending indices of a slice from the data set.\n",
    "rows_and_columns, which is expected to be a Boolean and has False as a default argument.\n",
    "Slices the data set using dataset[start:end].\n",
    "Loops through the slice, and for each iteration, prints a row and adds a new line after that row using print('\\n').\n",
    "The \\n in print('\\n') is a special character and won't be printed. Instead, the \\n character adds a new line, and we use print('\\n') to add some blank space between rows.\n",
    "Prints the number of rows and columns if rows_and_columns is True.\n",
    "dataset shouldn't have a header row, otherwise the function will print the wrong number of rows (one more row compared to the actual length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º pandas –∏ mathplotlib\n",
    "# –†–∏—Å–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ —Å—Ä–∞–∑—É –∂–µ\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from csv import reader\n",
    "\n",
    "plt.style.use('ggplot')  # –ö—Ä–∞—Å–∏–≤—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏\n",
    "plt.rcParams['figure.figsize'] = (15, 5)  # –†–∞–∑–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–æ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ - —Å—Ç–∞–≤–∏–º F –∏ —Ñ–∏–≥—É—Ä–Ω—ã–µ —Å–∫–æ–±–∫–∏\n",
    "#–ú–∞—Ç–∞–Ω–∞–ª–∏–∑, –õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞, –ú–∞—Ç—Å—Ç–∞–∏—Å—Ç–∏–∫–∞, –¢–µ–æ—Ä–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π, –ö–æ–º–±–∏–Ω–∞—Ç–æ—Ä–∏–∫–∞\n",
    "\n",
    "intensive = \"–û–±—É—á–µ–Ω–∏–µ –≤ —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ\"\n",
    "duration = \"130 –º–∏–Ω—É—Ç\"\n",
    "speaker = \"–°–∞—à–∞\"\n",
    "profession = \"–¥–∂—É–Ω–∏–æ—Ä\"\n",
    "whois = speaker + \", \" + profession\n",
    "print(f\"–°–µ–≥–æ–¥–Ω—è —É –Ω–∞—Å {intensive}, –ø—Ä–æ–≤–µ–¥–µ—Ç {whois}, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é {duration} –∏ —Ä–∞—Å—Å–∫–∞–∂–µ—Ç –æ —Ç–æ–º –∫–∞–∫ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –Ω–∞–ª–æ–≥–∏\")\n",
    "\n",
    "income = [12,26,43,54]\n",
    "for i in income:\n",
    "    tax = 0.13 * i\n",
    "    print(f\"–ï—Å–ª–∏ –í—ã –ø–æ–ª—É—á–∏–ª–∏ –¥–æ—Ö–æ–¥ –≤ —Ä–∞–∑–º–µ—Ä–µ {i}, –¥–æ–ª–∂–Ω—ã —É–ø–ª–∞—Ç–∏—Ç—å –Ω–∞–ª–æ–≥ –≤ —Ä–∞–∑–º–µ—Ä–µ {tax}\")\n",
    "    \n",
    "plt.plot(income)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### The Google Play data set ###\n",
    "opened_file = open('googleplaystore.csv', encoding='utf-8')\n",
    "read_file = reader(opened_file)\n",
    "android = list(read_file)\n",
    "android_header = android[0]\n",
    "android = android[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The App Store data set ###\n",
    "opened_file = open('AppleStore.csv', encoding='utf-8')\n",
    "read_file = reader(opened_file)\n",
    "ios = list(read_file)\n",
    "ios_header = ios[0]\n",
    "ios = ios[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for row in android:    \n",
    "    if len(row) != len(android_header):\n",
    "        print(android.index(row))     \n",
    "\n",
    "del android[10472]\n",
    "\n",
    "for row in ios:    \n",
    "    if len(row) != len(ios_header):\n",
    "        print(ios.index(row)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(android_header)\n",
    "print(ios_header)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Play data set has duplicate entries. Print a few duplicate rows to confirm.\n",
    "Count the number of duplicates\n",
    "use this information to build a criterion for removing the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_android = []\n",
    "duplicate_android = []\n",
    "for app in android:\n",
    "    check_name = app[0]\n",
    "    if check_name in unique_android:\n",
    "        duplicate_android.append(check_name)\n",
    "    else:\n",
    "        unique_android.append(check_name)\n",
    "        \n",
    "print(\"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π Google: \", len(unique_android))\n",
    "print(\"–î—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç—Ä–æ–∫ Google: \", len(duplicate_android))\n",
    "\n",
    "unique_ios = []\n",
    "duplicate_ios = []\n",
    "for app in ios:\n",
    "    check_name = app[0]\n",
    "    if check_name in unique_ios:\n",
    "        duplicate_ios.append(check_name)\n",
    "    else:\n",
    "        unique_ios.append(check_name)\n",
    "        \n",
    "print(\"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π Apple: \", len(unique_ios))\n",
    "print(\"–î—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç—Ä–æ–∫ Apple: \", len(duplicate_ios))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary where each key is a unique app name \n",
    "and the corresponding dictionary \n",
    "value is the highest number of reviews of that app.\n",
    "Use the dictionary you created above to remove the duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "\n",
    "print(\"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ —Å–ª–æ–≤–∞—Ä–µ Google: \", len(reviews_max))\n",
    "\n",
    "reviews_max_ios = {}\n",
    "for app in ios:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[5])\n",
    "    if name in reviews_max_ios and reviews_max_ios[name] < n_reviews:\n",
    "        reviews_max_ios[name] = n_reviews\n",
    "    elif name not in reviews_max_ios:\n",
    "        reviews_max_ios[name] = n_reviews\n",
    "\n",
    "print(\"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ —Å–ª–æ–≤–∞—Ä–µ Apple: \", len(reviews_max_ios))\n",
    "\n",
    "android_clean = []\n",
    "android_added = []\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])   \n",
    "    if (reviews_max[name] == n_reviews) and (name not in android_added):\n",
    "        android_clean.append(app)\n",
    "        android_added.append(name)\n",
    "\n",
    "ios_clean = []\n",
    "ios_added = []\n",
    "for app in ios:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[5])   \n",
    "    if (reviews_max_ios[name] == n_reviews) and (name not in ios_added):\n",
    "        ios_clean.append(app)\n",
    "        ios_added.append(name)\n",
    "            \n",
    "print(\"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ –æ—á–∏—â–µ–Ω–Ω–æ–º –ª–∏—Å—Ç–µ Google: \", len(android_clean))\n",
    "print(\"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ –æ—á–∏—â–µ–Ω–Ω–æ–º –ª–∏—Å—Ç–µ Apple: \", len(ios_clean))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The numbers corresponding to the characters we commonly use in an English text are all in the range 0 to 127, according to the ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eng_check(string):\n",
    "    x=0\n",
    "    for character in string:        \n",
    "        if ord(character) > 127:\n",
    "            x += 1\n",
    "    if x > 3:\n",
    "        return False        \n",
    "    else:\n",
    "        return True\n",
    "\n",
    "print(eng_check('Docs To Go‚Ñ¢ Free Office Suite'))\n",
    "print(eng_check('Instachat üòú'))\n",
    "print(eng_check('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠'))\n",
    "\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolating the free apps will be our last step in the data cleaning process. On the next screen, we're going to start analyzing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "android_free = []\n",
    "android_non_free = []\n",
    "for app in android_clean:\n",
    "    name = app[0]\n",
    "    n_price = app[7]   \n",
    "    if n_price == \"0\":\n",
    "        android_free.append(app)\n",
    "    else:\n",
    "        android_non_free.append(app)\n",
    "\n",
    "print(\"–ë–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π Google: \", len(android_free))\n",
    "print(\"–ü–ª–∞—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π Google: \", len(android_non_free))\n",
    "\n",
    "ios_free = []\n",
    "ios_non_free = []\n",
    "for app in ios_clean:\n",
    "    name = app[0]\n",
    "    n_price = app[4]   \n",
    "    if n_price == \"0.0\":\n",
    "        ios_free.append(app)\n",
    "    else:\n",
    "        ios_non_free.append(app)\n",
    "\n",
    "print(\"–ë–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π Apple: \", len(ios_free))\n",
    "print(\"–ü–ª–∞—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π Apple: \", len(ios_non_free))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_eng_only = []\n",
    "for app in android_free:\n",
    "    name = app[0]\n",
    "    if eng_check(name):\n",
    "        android_eng_only.append(app) \n",
    "\n",
    "ios_eng_only = []\n",
    "for app in ios_free:\n",
    "    name = app[1]\n",
    "    if eng_check(name):\n",
    "        ios_eng_only.append(app)\n",
    "        \n",
    "print(\"–ë–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π Google: \", len(android_eng_only))\n",
    "print(\"–ü–ª–∞—Ç–Ω—ã—Ö –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π Apple: \", len(ios_eng_only))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∏—Å–ª–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –ø–æ –∂–∞–Ω—Ä–∞–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_app_android = {}\n",
    "\n",
    "for app in android_eng_only:\n",
    "    genre = app[1]\n",
    "    if genre in popular_app_android:\n",
    "        popular_app_android[genre] += 1\n",
    "    else:\n",
    "        popular_app_android[genre]  = 1\n",
    "\n",
    "print(popular_app_android)\n",
    "\n",
    "popular_app_ios = {}\n",
    "\n",
    "for app in ios_eng_only:\n",
    "    genre = app[-5]\n",
    "    if genre in popular_app_ios:\n",
    "        popular_app_ios[genre] += 1\n",
    "    else:\n",
    "        popular_app_ios[genre]  = 1\n",
    "\n",
    "print(popular_app_ios)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—â–µ–º —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n",
    "–î–ª—è —ç—Ç–æ–≥–æ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏\n",
    "–î–æ–±–∞–≤–ª—è–µ–º —á–∏—Å–ª–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset, index):\n",
    "    table = {}\n",
    "    total = 0\n",
    "    \n",
    "    for row in dataset:\n",
    "        total += 1\n",
    "        value = row[index]\n",
    "        if value in table:\n",
    "            table[value] += 1\n",
    "        else:\n",
    "            table[value] = 1\n",
    "    \n",
    "    table_percentages = {}\n",
    "    for key in table:\n",
    "        percentage = (table[key] / total) * 100\n",
    "        table_percentages[key] = percentage \n",
    "    \n",
    "    return table_percentages\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "        \n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', round(entry[0], 2), \"%\")\n",
    "        \n",
    "final_ios = display_table(ios_eng_only, -5)\n",
    "print(final_ios)\n",
    "final_android = display_table(android_eng_only, 1)\n",
    "print(final_android)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ML —Å–æ–∑–¥–∞–µ—Ç—Å—è —á—Ç–æ–±—ã —á—Ç–æ-–Ω–∏–±—É–¥—å —É–ª—É—á—à–∏—Ç—å. \n",
    "#–ó–∞–¥–∞—á–∏ ML: –¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–¥–µ–æ\n",
    "#–≠—Ç–∞–ø –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è: —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –æ–±—É—á–µ–Ω–∏–µ, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏)\n",
    "#–£—á–∏–º –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö. –ù–∞–ø—Ä–∞–≤–∏—Ç—å –Ω–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ —Ü–µ–ª–∏, –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–¥–∞—á–∏\n",
    "#–ë–∞–∑–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ML: Sklearn, Pandas, Matplotlib\n",
    "\n",
    "#–î–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "\n",
    "print(android_header)\n",
    "android.Category.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_df.price.describe() #–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ –∏ –µ–≥–æ –∫–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "\n",
    "fixed_df.user_rating.value_counts() #–°–º–æ—Ç—Ä–∏–º –¥—Ä—É–≥—É—é –∫–æ–ª–æ–Ω–∫—É –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –≤ —á–∏—Å–ª–∞—Ö\n",
    "fixed_df.user_rating.value_counts().plot(kind = \"bar\") #–î–æ–±–∞–≤–ª—è–µ–º —á–µ—Ä–µ–∑ —Ç–æ—á–∫—É –∏ —Å–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∏—Ä—É–µ–º –≤—ã–¥–∞—á—É –≤—Å–µ–≥–æ –≤ –≥—Ä–∞—Ñ–µ\n",
    "#–ü–æ—Å–∫–æ–ª—å–∫—É –æ–Ω–∏ –∏–¥—É—Ç –ø–æ–¥—Ä—è–¥, —Ç–æ –≤—ã–¥–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ —è—á–µ–π–∫–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_df.user_rating.hist() #–†–∏—Å—É–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_df.prime_genre.value_counts().plot(kind = 'bar') #–†–∞–∑–≤–µ–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑. –ø–æ–Ω–∏–º–∞–µ–º —á—Ç–æ —É –Ω–∞—Å —Å–æ–±—Ä–∞–ª—Å—è –∑–∞ –¥–∞—Ç–∞—Å–µ—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(fixed_df, columns=['track_name', 'currency', 'prime_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#—Å—Ç—Ä–æ–∏–º –º–æ–¥–µ–ª—å\n",
    "#1 —ç—Ç–∞–ø - –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö \n",
    "#–ó–∞–º–µ–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫ –Ω–∞ 0 –∏ 1 \n",
    "\n",
    "fixed_df_transformed = pd.get_dummies(fixed_df, columns=['track_name', 'currency', 'prime_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–î–∞–Ω–Ω—ã–µ, –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ç–æ—Ä—ã—Ö —Ö–æ—Ç–∏–º –Ω–∞—É—á–∏—Ç—å—Å—è –¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "input_data = fixed_df_transformed.drop('user_rating_ver', axis=1)\n",
    "user_rating_ver = fixed_df_transformed.user_rating_ver #–¢–æ —á—Ç–æ –º—ã –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(input_data, user_rating_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{col:0 for col in input_data.columns}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
