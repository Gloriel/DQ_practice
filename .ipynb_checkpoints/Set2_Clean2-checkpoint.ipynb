{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings # отключим предупреждения Anaconda\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg' #графики в svg выглядят более четкими\n",
    "from pylab import rcParams #увеличим дефолтный размер графиков\n",
    "plt.style.use('ggplot')  # Красивые графики\n",
    "plt.rcParams['figure.figsize'] = (15, 5)  # Размер картинок\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "pd.options.display.float_format = '{:,.1f}'.format # Отображение чисел float с запятыми и 1 знаком после точки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_tests = pd.Series(['email', 'Email', 'e Mail', 'e mail', 'E-mail',\n",
    "              'e-mail', 'eMail', 'E-Mail', 'EMAIL', 'emails', 'Emails',\n",
    "              'E-Mails'])\n",
    "pattern = r\"\\be[\\-\\s]?mails?\\b\"\n",
    "email_mentions = titles.str.contains(pattern, flags=re.I).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn = pd.read_csv(\"hacker_news.csv\")\n",
    "titles = hn['title']\n",
    "sql_pattern = r\"SQL\"\n",
    "sql_counts = titles.str.contains(sql_pattern, flags=re.I).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn_sql = hn[hn['title'].str.contains(r\"\\w+SQL\", flags=re.I)].copy()\n",
    "hn_sql[\"flavor\"] = hn_sql[\"title\"].str.extract(r\"(\\w+SQL)\", re.I)\n",
    "hn_sql[\"flavor\"] = hn_sql[\"flavor\"].str.lower()\n",
    "sql_pivot = hn_sql.pivot_table(index=\"flavor\",values=\"num_comments\", aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"[Pp]ython ([\\d\\.]+)\"\n",
    "\n",
    "py_versions = titles.str.extract(pattern)\n",
    "py_versions_freq = dict(py_versions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_10_matches(pattern):\n",
    "    \"\"\"\n",
    "    Return the first 10 story titles that match\n",
    "    the provided regular expression\n",
    "    \"\"\"\n",
    "    all_matches = titles[titles.str.contains(pattern)]\n",
    "    first_10 = all_matches.head(10)\n",
    "    return first_10\n",
    "\n",
    "# pattern = r\"\\b[Cc]\\b\"\n",
    "pattern = r\"\\b[Cc]\\b[^.+]\"\n",
    "first_ten = first_10_matches(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(?<!Series\\s)\\b[Cc]\\b((?![+.])|\\.$)\"\n",
    "c_mentions = titles.str.contains(pattern).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\b(\\w+)\\s\\1\\b\"\n",
    "\n",
    "repeated_words = titles[titles.str.contains(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_variations = pd.Series(['email', 'Email', 'e Mail',\n",
    "                        'e mail', 'E-mail', 'e-mail',\n",
    "                        'eMail', 'E-Mail', 'EMAIL'])\n",
    "pattern = r\"\\be[-\\s]?mail\"\n",
    "email_uniform = email_variations.str.replace(pattern, \"email\", flags=re.I)\n",
    "titles_clean = titles.str.replace(pattern, \"email\", flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_urls = pd.Series([\n",
    " 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
    " 'http://www.interactivedynamicvideo.com/',\n",
    " 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
    " 'http://evonomics.com/advertising-cannot-maintain-internet-heres-solution/',\n",
    " 'HTTPS://github.com/keppel/pinn',\n",
    " 'Http://phys.org/news/2015-09-scale-solar-youve.html',\n",
    " 'https://iot.seeed.cc',\n",
    " 'http://www.bfilipek.com/2016/04/custom-deleters-for-c-smart-pointers.html',\n",
    " 'http://beta.crowdfireapp.com/?beta=agnipath',\n",
    " 'https://www.valid.ly?param',\n",
    " 'http://css-cursor.techstream.org'\n",
    "])\n",
    "pattern = r\"https?://([\\w\\-\\.]+)\"\n",
    "\n",
    "test_urls_clean = test_urls.str.extract(pattern, flags=re.I)\n",
    "domains = hn['url'].str.extract(pattern, flags=re.I)\n",
    "top_domains = domains.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `test_urls` is available from the previous screen\n",
    "pattern = r\"(https?)://([\\w\\.\\-]+)/?(.*)\"\n",
    "\n",
    "test_url_parts = test_urls.str.extract(pattern, flags=re.I)\n",
    "url_parts = hn['url'].str.extract(pattern, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = r\"(https?)://([\\w\\.\\-]+)/?(.*)\"\n",
    "pattern = r\"(?P<protocol>https?)://(?P<domain>[\\w\\.\\-]+)/?(?P<path>.*)\"\n",
    "url_parts = hn['url'].str.extract(pattern, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_cup_str = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"team_1\": \"France\",\n",
    "        \"team_2\": \"Croatia\",\n",
    "        \"game_type\": \"Final\",\n",
    "        \"score\" : [4, 2]\n",
    "    },\n",
    "    {\n",
    "        \"team_1\": \"Belgium\",\n",
    "        \"team_2\": \"England\",\n",
    "        \"game_type\": \"3rd/4th Playoff\",\n",
    "        \"score\" : [2, 0]\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "import json\n",
    "world_cup_obj = json.loads(world_cup_str)\n",
    "file = open(\"hn_2014.json\")\n",
    "hn = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_key(dict_, key):\n",
    "    # create a copy so we don't\n",
    "    # modify the original dict\n",
    "    modified_dict = dict_.copy()\n",
    "    del modified_dict[key]\n",
    "    return modified_dict\n",
    "hn_clean = []\n",
    "\n",
    "for d in hn:\n",
    "    new_d = del_key(d, 'createdAtI')\n",
    "    hn_clean.append(new_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOP VERSION\n",
    "#\n",
    "# hn_clean = []\n",
    "#\n",
    "# for d in hn:\n",
    "#     new_d = del_key(d, 'createdAtI')\n",
    "#     hn_clean.append(new_d)\n",
    "hn_clean = [del_key(d, 'createdAtI') for d in hn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [d['url'] for d in hn_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thousand_points = [d for d in hn_clean if d['points'] > 1000]\n",
    "num_thousand_points = len(thousand_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_comments(story):\n",
    "    return story['numComments']\n",
    "\n",
    "most_comments = max(hn_clean, key=get_num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multiply(a, b):\n",
    "#    return a * b\n",
    "multiply = lambda a, b: a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn_sorted_points = sorted(hn_clean, key=lambda d: d['points'], reverse=True)\n",
    "top_5_titles = [d['title'] for d in hn_sorted_points[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn_df = pd.DataFrame(hn_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = hn_df['tags']\n",
    "has_four_tags = tags.apply(len) == 4\n",
    "four_tags = tags[has_four_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_tag(l):\n",
    "#     return l[-1] if len(l) == 4 else None\n",
    "cleaned_tags = tags.apply(lambda l: l[-1] if len(l) == 4 else None)\n",
    "hn_df['tags'] = cleaned_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvc = pd.read_csv(\"nypd_mvc_2018.csv\")\n",
    "null_counts = mvc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "killed_cols = [col for col in mvc.columns if 'killed' in col]\n",
    "killed = mvc[killed_cols].copy()\n",
    "killed_manual_sum = killed.iloc[:,:3].sum(axis=1)\n",
    "killed_mask = killed_manual_sum != killed['total_killed']\n",
    "killed_non_eq = killed[killed_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the killed values\n",
    "killed['total_killed'] = killed['total_killed'].mask(killed['total_killed'].isnull(), killed_manual_sum)\n",
    "killed['total_killed'] = killed['total_killed'].mask(killed['total_killed'] != killed_manual_sum, np.nan)\n",
    "\n",
    "# Create an injured dataframe and manually sum values\n",
    "injured = mvc[[col for col in mvc.columns if 'injured' in col]].copy()\n",
    "injured_manual_sum = injured.iloc[:,:3].sum(axis=1)\n",
    "injured['total_injured'] = injured['total_injured'].mask(injured['total_injured'].isnull(), injured_manual_sum)\n",
    "injured['total_injured'] = injured['total_injured'].mask(injured['total_injured'] != injured_manual_sum, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvc['total_injured'] = injured['total_injured']\n",
    "mvc['total_killed'] = killed['total_killed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_null_correlations(df):\n",
    "    # create a correlation matrix only for columns with at least\n",
    "    # one missing value\n",
    "    cols_with_missing_vals = df.columns[df.isnull().sum() > 0]\n",
    "    missing_corr = df[cols_with_missing_vals].isnull().corr()\n",
    "    \n",
    "    # create a mask to avoid repeated values and make\n",
    "    # the plot easier to read\n",
    "    missing_corr = missing_corr.iloc[1:, :-1]\n",
    "    mask = np.triu(np.ones_like(missing_corr), k=1)\n",
    "    \n",
    "    # plot a heatmap of the values\n",
    "    plt.figure(figsize=(20,14))\n",
    "    ax = sns.heatmap(missing_corr, vmin=-1, vmax=1, cbar=False,\n",
    "                     cmap='RdBu', mask=mask, annot=True)\n",
    "    \n",
    "    # format the text in the plot to make it easier to read\n",
    "    for text in ax.texts:\n",
    "        t = float(text.get_text())\n",
    "        if -0.05 < t < 0.01:\n",
    "            text.set_text('')\n",
    "        else:\n",
    "            text.set_text(round(t, 2))\n",
    "        text.set_fontsize('x-large')\n",
    "    plt.xticks(rotation=90, size='x-large')\n",
    "    plt.yticks(rotation=0, size='x-large')\n",
    "\n",
    "    plt.show()\n",
    "veh_cols = [c for c in mvc.columns if 'vehicle' in c]\n",
    "plot_null_correlations(mvc[veh_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_labels = ['v_number', 'vehicle_missing', 'cause_missing']\n",
    "\n",
    "vc_null_data = []\n",
    "\n",
    "# for v in range(1,6):\n",
    "#     v_col = 'vehicle_{}'.format(v)\n",
    "#     c_col = 'cause_vehicle_{}'.format(v)\n",
    "for v in range(1,6):\n",
    "    v_col = 'vehicle_{}'.format(v)\n",
    "    c_col = 'cause_vehicle_{}'.format(v)\n",
    "    \n",
    "    v_null = (mvc[v_col].isnull() & mvc[c_col].notnull()).sum()\n",
    "    c_null = (mvc[c_col].isnull() & mvc[v_col].notnull()).sum()\n",
    "    \n",
    "    vc_null_data.append([v, v_null, c_null])\n",
    "\n",
    "vc_null_df = pd.DataFrame(vc_null_data, columns=col_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cols = [c for c in mvc.columns if c.startswith(\"vehicle\")]\n",
    "vehicles = mvc[v_cols]\n",
    "vehicles_1d = vehicles.stack()\n",
    "vehicles_counts = vehicles_1d.value_counts()\n",
    "top10_vehicles = vehicles_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_missing():\n",
    "    v_missing_data = []\n",
    "\n",
    "    for v in range(1,6):\n",
    "        v_col = 'vehicle_{}'.format(v)\n",
    "        c_col = 'cause_vehicle_{}'.format(v)\n",
    "\n",
    "        v_missing = (mvc[v_col].isnull() & mvc[c_col].notnull()).sum()\n",
    "        c_missing = (mvc[c_col].isnull() & mvc[v_col].notnull()).sum()\n",
    "\n",
    "        v_missing_data.append([v, v_missing, c_missing])\n",
    "\n",
    "    col_labels = columns=[\"vehicle_number\", \"vehicle_missing\", \"cause_missing\"]\n",
    "    return pd.DataFrame(v_missing_data, columns=col_labels)\n",
    "\n",
    "summary_before = summarize_missing()\n",
    "\n",
    "# for v in range(1,6):\n",
    "#     v_col = 'vehicle_{}'.format(v)\n",
    "#     c_col = 'cause_vehicle_{}'.format(v)\n",
    "for v in range(1,6):\n",
    "    v_col = 'vehicle_{}'.format(v)\n",
    "    c_col = 'cause_vehicle_{}'.format(v)\n",
    "    \n",
    "    v_missing_mask = mvc[v_col].isnull() & mvc[c_col].notnull()\n",
    "    c_missing_mask = mvc[c_col].isnull() & mvc[v_col].notnull()\n",
    "\n",
    "    mvc[v_col] = mvc[v_col].mask(v_missing_mask, \"Unspecified\")\n",
    "    mvc[c_col] = mvc[c_col].mask(c_missing_mask, \"Unspecified\")\n",
    "\n",
    "summary_after = summarize_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_data = pd.read_csv('supplemental_data.csv')\n",
    "\n",
    "location_cols = ['location', 'on_street', 'off_street', 'borough']\n",
    "null_before = mvc[location_cols].isnull().sum()\n",
    "for col in location_cols:\n",
    "    mvc[col] = mvc[col].mask(mvc[col].isnull(), sup_data[col])\n",
    "\n",
    "null_after = mvc[location_cols].isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
